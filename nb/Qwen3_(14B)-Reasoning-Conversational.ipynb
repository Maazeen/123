{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maazeen/123/blob/main/nb/Qwen3_(14B)-Reasoning-Conversational.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBV5cEdQnDgq"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcuK3N2CnDgv"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwmL6m6VoRwh",
        "outputId": "e060afc6-bad4-4320-93ac-ef2c927b42d4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NWZORWlnDgw"
      },
      "source": [
        "Unsloth now supports Text-to-Speech (TTS) models. Read our [guide here](https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning).\n",
        "\n",
        "Read our **[Qwen3 Guide](https://docs.unsloth.ai/basics/qwen3-how-to-run-and-fine-tune)** and check out our new **[Dynamic 2.0](https://docs.unsloth.ai/basics/unsloth-dynamic-2.0-ggufs)** quants which outperforms other quantization methods!\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQuYzD1CnDgw"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujiLesGbnDgx"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "    !pip install transformers==4.51.3\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iajq1W8ipjyK"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmUBVEnvCDJv"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "fourbit_models = [\n",
        "    \"unsloth/Qwen3-1.7B-unsloth-bnb-4bit\", # Qwen 14B 2x faster\n",
        "    \"unsloth/Qwen3-4B-unsloth-bnb-4bit\",\n",
        "    \"unsloth/Qwen3-8B-unsloth-bnb-4bit\",\n",
        "    \"unsloth/Qwen3-14B-unsloth-bnb-4bit\",\n",
        "    \"unsloth/Qwen3-32B-unsloth-bnb-4bit\",\n",
        "\n",
        "    # 4bit dynamic quants for superior accuracy and low memory use\n",
        "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
        "    \"unsloth/Phi-4\",\n",
        "    \"unsloth/Llama-3.1-8B\",\n",
        "    \"unsloth/Llama-3.2-3B\",\n",
        "    \"unsloth/orpheus-3b-0.1-ft-unsloth-bnb-4bit\" # [NEW] We support TTS models!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Qwen3-14B\",\n",
        "    max_seq_length = 2048,   # Context length - can be longer, but uses more memory\n",
        "    load_in_4bit = True,     # 4bit uses much less memory\n",
        "    load_in_8bit = False,    # A bit more accurate, uses 2x memory\n",
        "    full_finetuning = False, # We have full finetuning now!\n",
        "    # token = \"hf_...\",      # use one if using gated models\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bZsfBuZDeCL"
      },
      "outputs": [],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 32,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 32,  # Best to choose alpha = rank or rank*2\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,   # We support rank stabilized LoRA\n",
        "    loftq_config = None,  # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "Qwen3 has both reasoning and a non reasoning mode. So, we should use 2 datasets:\n",
        "\n",
        "1. We use the [Open Math Reasoning]() dataset which was used to win the [AIMO](https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-2/leaderboard) (AI Mathematical Olympiad - Progress Prize 2) challenge! We sample 10% of verifiable reasoning traces that used DeepSeek R1, and whicht got > 95% accuracy.\n",
        "\n",
        "2. We also leverage [Maxime Labonne's FineTome-100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset in ShareGPT style. But we need to convert it to HuggingFace's normal multiturn format as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kyTw2n1edte"
      },
      "outputs": [],
      "source": [
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "### Instruction:\n",
        "{}\n",
        "### Input:\n",
        "{}\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    # Access the correct column names from your dataset\n",
        "    instructions = examples[\"prompt\"] # Changed from \"prompt\" to \"instruction\"\n",
        "    inputs = examples[\"query\"] # Changed from \"context\" to \"input\"\n",
        "    outputs = examples[\"xml\"] # Changed from \"response\" to \"output\"\n",
        "\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return {\"text\": texts}\n",
        "\n",
        "# Apply the formatting function to your dataset\n",
        "\n",
        "from datasets import Dataset\n",
        "dataset_path = \"/content/drive/My Drive/Colab Notebooks/dataset/fbdataset.arrow\"\n",
        "dataset = Dataset.from_file(\"/content/drive/My Drive/Colab Notebooks/dataset/fbdataset.arrow\")\n",
        "print(dataset)\n",
        "# Apply the function directly to the dataset\n",
        "formatted_dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "\n",
        "# Print some examples from the formatted dataset to check the results\n",
        "print(formatted_dataset[\"text\"][:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 2048\n",
        "\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "print(dataset.column_names)\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = formatted_dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60, # Set num_train_epochs = 1 for full training runs\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "KhguC20zpQi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ],
      "metadata": {
        "id": "cBoOJOB4pS1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-gNQ-MNHpS3g",
        "outputId": "c5396e0a-95f2-4f8d-8ef5-c97655759e8a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 118 | Num Epochs = 5 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 128,450,560/14,000,000,000 (0.92% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiddiquemazin\u001b[0m (\u001b[33msiddiquemazin-manipal-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_103548-b83ugw6i</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/siddiquemazin-manipal-institute-of-technology/huggingface/runs/b83ugw6i' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/siddiquemazin-manipal-institute-of-technology/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/siddiquemazin-manipal-institute-of-technology/huggingface' target=\"_blank\">https://wandb.ai/siddiquemazin-manipal-institute-of-technology/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/siddiquemazin-manipal-institute-of-technology/huggingface/runs/b83ugw6i' target=\"_blank\">https://wandb.ai/siddiquemazin-manipal-institute-of-technology/huggingface/runs/b83ugw6i</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 37:24, Epoch 4.20/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.200400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.167200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.211500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.223100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.102900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.930100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.041600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.822400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.759700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.698300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.676300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.545000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.704500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.560600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.115800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.534000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.644800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.621500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.442100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.542500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.456300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.433300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.402100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.290700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.410800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.494500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.307300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.350300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.759000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.395400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.373000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.402400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.305500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.382100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.413900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.428400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.415900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.375900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.353700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.290500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.363500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.514700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.655700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.247100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.389400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.311200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.349400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.413800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.371300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.312800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.305200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.447400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.314900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.401400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.372400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.311400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.636400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.302900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 38:05, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.200400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.167200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.211500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.223100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.102900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.930100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.041600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.822400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.759700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.698300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.676300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.545000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.704500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.560600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.115800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.534000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.644800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.621500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.442100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.542500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.456300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.433300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.402100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.290700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.410800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.494500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.307300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.350300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.759000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.395400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.373000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.402400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.305500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.382100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.413900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.428400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.415900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.375900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.353700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.290500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.363500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.514700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.655700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.247100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.389400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.311200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.349400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.413800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.371300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.312800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.305200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.447400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.314900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.401400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.372400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.311400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.636400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.302900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.271600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.328000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"You are an AI assistant specializing in IEC61499 applications and EcoStruxure Automation Expert. Generate the XML for the following query:\", # instruction\n",
        "        \"Create an application to permit the motor2Op to run in Forward direction, when Limit switch is detected, Limit switch means digital input function block is connected to permCondItem with condCause set to Active1 and permCondItem is connected to Motor2Op block\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 1064, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-lMZDYMpS5f",
        "outputId": "708a0595-85fb-4abf-f973-1784a7c3506e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n### Instruction:\\nYou are an AI assistant specializing in IEC61499 applications and EcoStruxure Automation Expert. Generate the XML for the following query:\\n### Input:\\nCreate an application to permit the motor2Op to run in Forward direction, when Limit switch is detected, Limit switch means digital input function block is connected to permCondItem with condCause set to Active1 and permCondItem is connected to Motor2Op block\\n### Response:\\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<!DOCTYPE FBType SYSTEM \"../LibraryElement.dtd\">\\n<FBType GUID=\"23456789-1234-5678-9012-345678901234\" Name=\"Motor2Op\" Comment=\"Forward Motor Operation\" Namespace=\"Main\">\\n  <Identification Standard=\"61499-2\" />\\n  <VersionInfo Organization=\"YourOrganization\" Version=\"1.0\" Author=\"YourName\" Date=\"YYYY-MM-DD\" Remarks=\"Forward Motor Operation\" />\\n  <InterfaceList>\\n    <EventInputs>\\n      <Event Name=\"REQ\" Comment=\"Request to run the motor forward\">\\n        <With Var=\"Forward\" />\\n        <With Var=\"LimitSwitch\" />\\n      </Event>\\n      <Event Name=\"CNF\" Comment=\"Confirmation of operation\" />\\n    </EventInputs>\\n    <EventOutputs>\\n      <Event Name=\"CNF\" Comment=\"Confirmation of operation\" />\\n    </EventOutputs>\\n    <InputVars>\\n      <VarDeclaration Name=\"Forward\" Type=\"BOOL\" Comment=\"Signal to run motor forward\" />\\n      <VarDeclaration Name=\"LimitSwitch\" Type=\"BOOL\" Comment=\"Limit switch input\" />\\n    </InputVars>\\n  </InterfaceList>\\n  <BasicFB>\\n    <Attribute Name=\"FBType.Basic.Algorithm.Order\" Value=\"RunForward\" />\\n    <ECC>\\n      <ECState Name=\"START\" Comment=\"Initial State\" x=\"100\" y=\"100\" />\\n      <ECState Name=\"RUNNING\" Comment=\"Running the motor forward\" x=\"1000\" y=\"500\">\\n        <ECAction Algorithm=\"RunForward\" Output=\"CNF\" />\\n      </ECState>\\n      <ECTransition Source=\"START\" Destination=\"RUNNING\" Condition=\"REQ\" x=\"552.8294\" y=\"221.8259\">\\n        <Attribute Name=\"Configuration.Transaction.BezierPoints\" Value=\"129.1856,42.26745,178.6578,47.97219\" />\\n      </ECTransition>\\n      <ECTransition Source=\"RUNNING\" Destination=\"START\" Condition=\"1\" x=\"532.1176\" y=\"533.2155\">\\n        <Attribute Name=\"Configuration.Transaction.BezierPoints\" Value=\"175.8382,111.5942,126.366,105.8994\" />\\n      </ECTransition>\\n    </ECC>\\n    <Algorithm Name=\"RunForward\" Comment=\"Algorithm to run the motor forward\">\\n      <ST><![CDATA[\\n        IF Forward AND LimitSwitch THEN\\n          // Motor is running forward\\n        END_IF;\\n      ]]></ST>\\n    </Algorithm>\\n  </BasicFB>\\n</FBType>\\n ?><?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<!DOCTYPE FBType SYSTEM \"../LibraryElement.dtd\">\\n<FBType GUID=\"23456789-1234-5678-9012-345678901234\" Name=\"LimitSwitch\" Comment=\"Limit switch detection\" Namespace=\"Main\">\\n  <Identification Standard=\"61499-2\" />\\n  <VersionInfo Organization=\"YourOrganization\" Version=\"1.0\" Author=\"YourName\" Date=\"YYYY-MM-DD\" Remarks=\"Limit switch detection\" />\\n  <InterfaceList>\\n    <EventInputs>\\n      <Event Name=\"REQ\" Comment=\"Request to check the limit switch\">\\n        <With Var=\"SwitchState\" />\\n      </Event>\\n    </EventInputs>\\n    <EventOutputs>\\n      <Event Name=\"CNF\" Comment=\"Confirmation of limit switch state\" />\\n    </EventOutputs>\\n    <OutputVars>\\n      <VarDeclaration Name=\"LimitSwitch\" Type=\"BOOL\" Comment=\"Limit switch state\" />\\n    </OutputVars>\\n  </InterfaceList>\\n  <BasicFB>\\n    <Attribute Name=\"FBType.Basic.Algorithm.Order\" Value=\"CheckLimitSwitch\" />\\n    <ECC>\\n      <ECState Name=\"START\" Comment=\"Initial State\" x=\"100\" y=\"100\" />\\n      <ECState Name=\"CHECKING\" Comment=\"Checking limit switch\" x=\"1000\" y=\"500\">\\n        <ECAction Algorithm=\"CheckLimitSwitch\" Output=\"CNF\" />\\n      </ECState>\\n      <ECTransition Source=\"START\" Destination=\"CHECKING\" Condition=\"REQ\" x=\"552.8294\" y=\"221.8259\">\\n        <Attribute Name=\"Configuration.Transaction.BezierPoints\" Value=\"129.1856,42.26745,178.6578,47.97219\" />\\n      </ECTransition>\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define the prompt template\n",
        "prompt_template = \"\"\"Generate IEC61499 XML for the following description:\n",
        "{input}\n",
        "\n",
        "XML Output:\n",
        "\"\"\"\n",
        "\n",
        "# Function to extract XML from the model output\n",
        "\n",
        "\n",
        "def extract_xml(text):\n",
        "    # Remove the <s> and </s> tags if present\n",
        "    text = re.sub(r'^<s>|</s>$', '', text.strip())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Pattern for FBType XML, accounting for potential newlines and incomplete XML\n",
        "    fbtype_pattern = r'(<\\?xml[\\s\\S]*?(?:</FBType>|$))'\n",
        "    # Pattern for Application XML, accounting for potential newlines and incomplete XML\n",
        "    application_pattern = r'(<Application[\\s\\S]*?(?:</Application>|$))'\n",
        "\n",
        "    # Try to match FBType XML first\n",
        "    fbtype_match = re.search(fbtype_pattern, text, re.DOTALL)\n",
        "    if fbtype_match:\n",
        "        return fbtype_match.group(1)\n",
        "\n",
        "    # If no FBType XML found, try to match Application XML\n",
        "    application_match = re.search(application_pattern, text, re.DOTALL)\n",
        "    if application_match:\n",
        "        return application_match.group(1)\n",
        "\n",
        "    # If neither is found, try to find any XML-like structure\n",
        "    xml_pattern = r'(<[\\s\\S]*?>)'\n",
        "    xml_match = re.search(xml_pattern, text, re.DOTALL)\n",
        "    if xml_match:\n",
        "        return f\"Partial XML found:\\n{xml_match.group(1)}\"\n",
        "\n",
        "    # If no XML-like structure is found, return an error message\n",
        "    return \"Error: No valid XML structure found in the response.\"\n",
        "\n",
        "\n",
        "# Prepare the input\n",
        "input_text =  \"Create a 61499 function block for xor. Functionality: This Structured Text code implements an XOR (Exclusive OR) logic gate. It outputs TRUE only when one of the input signals IN1 or IN2 is TRUE, but not both.. Inputs: IN_VAR (REAL), IN1 (BOOL), IN2 (BOOL). Outputs: OUT_VAR (REAL), OUT (BOOL). Events: REQ: Request execution, CNF: Confirm execution.\"\n",
        "prompt = prompt_template.format(input=input_text)\n",
        "\n",
        "# Tokenize the input\n",
        "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n",
        "inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate the output\n",
        "outputs = model.generate(**inputs, max_new_tokens=2064, use_cache=True)\n",
        "\n",
        "# Decode the output\n",
        "decoded_output = tokenizer.batch_decode(outputs)[0]\n",
        "\n",
        "# Extract and print only the XML content\n",
        "xml_output = extract_xml(decoded_output)\n",
        "print(xml_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52F7w0a4pS7n",
        "outputId": "807fc883-af38-4048-8029-f82c82c28c8e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
            "<!DOCTYPE FBType SYSTEM \"../LibraryElement.dtd\">\n",
            "<FBType GUID=\"12345678-9abc-def0-1234-56789abcdef0\" Name=\"XOR\" Comment=\"Exclusive OR Logic Gate\" Namespace=\"Main\">\n",
            "  <Identification Standard=\"61499-2\" />\n",
            "  <VersionInfo Organization=\"YourOrganization\" Version=\"1.0\" Author=\"YourName\" Date=\"YYYY-MM-DD\" Remarks=\"Exclusive OR Logic Function\" />\n",
            "  <InterfaceList>\n",
            "    <EventInputs>\n",
            "      <Event Name=\"REQ\" Comment=\"Request execution\">\n",
            "        <With Var=\"IN_VAR\" />\n",
            "        <With Var=\"IN1\" />\n",
            "        <With Var=\"IN2\" />\n",
            "      </Event>\n",
            "    </EventInputs>\n",
            "    <EventOutputs>\n",
            "      <Event Name=\"CNF\" Comment=\"Confirm execution\">\n",
            "        <With Var=\"OUT_VAR\" />\n",
            "        <With Var=\"OUT\" />\n",
            "      </Event>\n",
            "    </EventOutputs>\n",
            "    <InputVars>\n",
            "      <VarDeclaration Name=\"IN_VAR\" Type=\"REAL\" Comment=\"Input signal for OUT_VAR\" />\n",
            "      <VarDeclaration Name=\"IN1\" Type=\"BOOL\" Comment=\"First input signal for OUT\" />\n",
            "      <VarDeclaration Name=\"IN2\" Type=\"BOOL\" Comment=\"Second input signal for OUT\" />\n",
            "    </InputVars>\n",
            "    <OutputVars>\n",
            "      <VarDeclaration Name=\"OUT_VAR\" Type=\"REAL\" Comment=\"Output signal for OUT_VAR\" />\n",
            "      <VarDeclaration Name=\"OUT\" Type=\"BOOL\" Comment=\"Output signal for OUT\" />\n",
            "    </OutputVars>\n",
            "  </InterfaceList>\n",
            "  <BasicFB>\n",
            "    <Attribute Name=\"FBType.Basic.Algorithm.Order\" Value=\"REQ\" />\n",
            "    <ECC>\n",
            "      <ECState Name=\"START\" Comment=\"Initial State\" x=\"100\" y=\"100\" />\n",
            "      <ECState Name=\"REQ\" Comment=\"Executing XOR logic\" x=\"1000\" y=\"550\">\n",
            "        <ECAction Algorithm=\"REQ\" Output=\"CNF\" />\n",
            "      </ECState>\n",
            "      <ECTransition Source=\"START\" Destination=\"REQ\" Condition=\"REQ\" x=\"576.1696\" y=\"285.3659\" />\n",
            "      <ECTransition Source=\"REQ\" Destination=\"START\" Condition=\"1\" x=\"515.1875\" y=\"527.3125\" />\n",
            "    </ECC>\n",
            "    <Algorithm Name=\"REQ\" Comment=\"XOR logic algorithm\">\n",
            "      <ST><![CDATA[\n",
            "        OUT_VAR := IN_VAR;\n",
            "        OUT := IN1 XOR IN2;\n",
            "      ]]></ST>\n",
            "    </Algorithm>\n",
            "  </BasicFB>\n",
            "</FBType>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"lora_model\") # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwuZbdQapS9k",
        "outputId": "0b37fd55-62ec-4bd6-d854-da6c55f31ebe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/vocab.json',\n",
              " 'lora_model/merges.txt',\n",
              " 'lora_model/added_tokens.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DHNG310tpS_o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTZICZtie3lQ"
      },
      "source": [
        "Let's see the structure of both datasets:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35b32ea6"
      },
      "source": [
        "It appears the Qwen3-14B model is too large for the available memory even with 4-bit quantization and `device_map=\"auto\"`. The error indicates issues with fitting offloaded layers.\n",
        "\n",
        "To resolve this, you can try using a smaller model from the Unsloth library that is better suited for the memory constraints of a T4 GPU. Models like Qwen3-7B or smaller should fit.\n",
        "\n",
        "Here's an example of how you would load the Qwen3-7B model instead:"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}